

# üß† Stroke Prediction ‚Äì Machine Learning Pipeline

> End-to-end machine learning workflow for predicting stroke risk using structured health data.

---

## üìå Project Overview

This project implements a complete supervised machine learning pipeline for **binary classification (Stroke / No Stroke)**.

The notebook includes:

* Data inspection and preprocessing
* Exploratory Data Analysis (EDA)
* Outlier detection
* Missing value treatment
* Categorical encoding
* Feature selection
* Handling class imbalance (SMOTE)
* Model training (multiple algorithms)
* Hyperparameter tuning (Optuna)
* Model persistence (Pickle)

The final optimized model is saved for reuse and deployment.

---

## üìÇ Project Structure

```
‚îú‚îÄ‚îÄ code.ipynb
‚îú‚îÄ‚îÄ stroke-data
‚îú‚îÄ‚îÄ README.md
```

---

## üßæ Dataset Description

The dataset contains patient-level medical and demographic information:

| Feature           | Description             |
| ----------------- | ----------------------- |
| age               | Patient age             |
| gender            | Male / Female           |
| hypertension      | Binary indicator        |
| heart_disease     | Binary indicator        |
| ever_married      | Yes / No                |
| work_type         | Employment category     |
| Residence_type    | Urban / Rural           |
| avg_glucose_level | Blood glucose           |
| bmi               | Body Mass Index         |
| smoking_status    | Smoking history         |
| stroke            | Target variable (0 / 1) |

---

# üìä Notebook Workflow (Cell-wise Explanation)

---

## 1Ô∏è‚É£ Importing Libraries

Libraries used:

* `pandas`, `numpy` ‚Üí Data handling
* `matplotlib`, `plotly` ‚Üí Visualization
* `sklearn` ‚Üí ML models & preprocessing
* `imblearn` ‚Üí SMOTE
* `optuna` ‚Üí Hyperparameter tuning
* `pickle` ‚Üí Model saving

---

## 2Ô∏è‚É£ Data Loading & Inspection

### Cells Performed:

* `df.shape`
* `df.info()`
* `df.isnull().sum()`
* `df.head()`

### Why:

To understand:

* Dataset size
* Data types
* Missing values
* Initial data structure

This step guides preprocessing decisions.

---

## 3Ô∏è‚É£ Outlier Detection

### Technique Used:

* Boxplots (Plotly)

### Why:

Outliers can distort model learning, especially in distance-based models.

Boxplots help visualize:

* Distribution spread
* Extreme values
* Skewness in features like BMI and age

---

## 4Ô∏è‚É£ Missing Value Treatment

### Steps Performed:

* Converted BMI to numeric
* Mean imputation for BMI
* Applied KNNImputer where necessary
* Removed remaining null rows

### Why:

Machine learning models cannot handle missing values directly.
Imputation ensures no data leakage and consistent model training.

---

## 5Ô∏è‚É£ Categorical Encoding

### Transformations:

* Gender ‚Üí Binary encoding
* Ever_married ‚Üí Binary encoding
* Residence_type ‚Üí Binary encoding
* Dropped ID column
* Removed rare "Other" category

### Why:

ML models require numerical inputs.
Encoding ensures compatibility while preserving information.

ID column was removed because it carries no predictive value.

---

## 6Ô∏è‚É£ Target Variable Analysis

The dataset showed strong imbalance:

* ~95% No Stroke
* ~5% Stroke

### Why this matters:

Accuracy alone becomes misleading in imbalanced datasets.

Therefore, F1-score was considered important during evaluation.

---

## 7Ô∏è‚É£ Correlation & Multicollinearity Check

### Methods Used:

* Correlation matrix
* Heatmap
* Variance Inflation Factor (VIF)

### Why:

To detect:

* Highly correlated features
* Redundant predictors
* Multicollinearity issues

No severe multicollinearity was found.

---

## 8Ô∏è‚É£ Feature Selection

### Method Used:

Random Forest Feature Importance

### Selected Important Features:

* Age
* Gender
* BMI
* Residence_type

### Why:

Tree-based models provide feature importance scores.

Selecting top features:

* Reduces noise
* Improves generalization
* Prevents overfitting

---

## 9Ô∏è‚É£ Train-Test Split

```python
train_test_split(X, y, test_size=0.3, random_state=42)
```

### Why:

To evaluate model performance on unseen data and prevent overfitting.

---

## üîü Handling Class Imbalance ‚Äì SMOTE

### Technique Used:

Synthetic Minority Oversampling Technique (SMOTE)

### Why:

The minority class (stroke cases) was underrepresented.

SMOTE:

* Generates synthetic minority samples
* Balances training data
* Improves recall and F1-score

SMOTE was applied **only on training data** to prevent data leakage.

---

## 1Ô∏è‚É£1Ô∏è‚É£ Model Training

Models trained:

* K-Nearest Neighbors (KNN)
* Decision Tree
* Random Forest
* Gradient Boosting

Each model was implemented using a **Pipeline** including:

* StandardScaler
* Classifier

### Why StandardScaler:

Some algorithms (KNN, Gradient Boosting) perform better when features are scaled to similar ranges.

Pipeline ensures:

* No data leakage
* Reproducibility
* Clean workflow

---

## 1Ô∏è‚É£2Ô∏è‚É£ Hyperparameter Tuning ‚Äì Optuna

Optuna was used to optimize model parameters.

### Why:

Manual tuning is inefficient and inconsistent.

Optuna:

* Automatically searches parameter space
* Uses intelligent optimization strategy
* Improves model performance systematically

Best performing model:
**Gradient Boosting (Optimized)**

---

## 1Ô∏è‚É£3Ô∏è‚É£ Model Evaluation

Metrics used:

* Accuracy
* F1 Score
* Classification Report

### Why F1-score:

Because dataset is imbalanced, F1-score balances Precision and Recall.

---

## üíæ Model Saving

```python
pickle.dump(best_pipeline, open("stroke_prediction_model.sav", "wb"))
```

### Why:

To:

* Reuse trained model
* Avoid retraining
* Enable deployment

---

# üèÅ Final Model

* Algorithm: Gradient Boosting
* Hyperparameters: Optimized using Optuna
* Imbalance Handling: SMOTE
* Evaluation Metric: F1 Score

The trained model is saved as:

```
stroke_prediction_model.sav
```

---

# üîÅ Reproducibility Notes

To run the project:

```bash
pip install pandas numpy scikit-learn imbalanced-learn optuna plotly
```

Then execute:

```
code.ipynb
```

---

# üë®‚Äçüíª Author

**Darshan Nyati**
AI & Machine Learning Enthusiast



Tell me the style you prefer.
